<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Atsuyuki Miyai 宮井 淳行</title>

  <meta name="author" content="Atsuyuki Miyai 宮井 淳行">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <meta name="google-site-verification" content="31ZvV8lDKRzmoX4jcWhS1mvt2mwfbRqbmh8XR1LRI1U" />
</head>

<body>
  
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Atsuyuki Miyai 宮井 淳行</name>
              </p>
              <p>
                <font size="4">I'm Atsuyuki Miyai.  Now, I'm a 2nd-year master's student at The University of Tokyo.
                I'm a member of <a href="http://www.hal.t.u-tokyo.ac.jp/lab/ja/index_1.xhtml"><font size="4">Aizawa Yamakata Matsui Lab </font></a>, where I work on computer vision and machine learning. <br> 
                My supervisor is <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja"><font size="4">Prof. Kiyoharu Aizawa</font></a>. <br>
                My research collaborators are <a href="https://yu1ut.com/"><font size="4">Dr. Qing Yu</font></a> (LINE CV lab.) and <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/"><font size="4">Prof. Go Irie</font></a> (Tokyo Univ. of Science).<br>
                <br>
                My research focuses on the safety of large pre-trained neural networks. In particular, I put an emphasis on defining new problems and aim to provide a simple, baseline approach to give insights. </font>

              </p> 
              <p style="text-align:center">
                <a href="mailto:miyai@hal.t.u-tokyo.ac.jp">Email</a> &nbsp/&nbsp
                <a href="https://github.com/AtsuMiyai">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.jp/citations?hl=ja&authuser=1&user=LaobWL8AAAAJ">Google Scholar</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/top_imaze.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/top_image/top_image.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                    <heading> <font size="6"> Education </font></heading>
                    <p>
                      <strong> <font size="4"> The University of Tokyo </font></strong><br>
                      Ph.D. in Graduate School of Information Science and Technology <br>
                      Supervisor: Prof. Toshihiko Yamasaki <br>
                      <em>2024.4 (to be) - </em>
                    </p>
                    
                    <p>
                      <strong> <font size="4"> The University of Tokyo </font></strong><br>
                      M.S. in Graduate School of Interdisciplinary Information Studies <br>
                      Supervisor: Prof. Kiyoharu Aizawa <br>
                      <em>2022.4 - present</em>
                    </p>
                    
                    <p>
                      <strong> <font size="4"> The University of Tokyo  </font></strong><br>
                      B.S. in Under Graduate School of Engineering<br>
                      Information and Communication Engineering <br> 
                      Supervisor: Prof. Kiyoharu Aizawa <br>
                      <em>2018.4 - 2022.3</em>
                    </p>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading> <font size="6"> News </font></heading>
                  <p>
                    <papertitle>
                      <span style="font-size:18px; font-weight:normal;">
                        2024.3: Our new work (preliminary version) has been accepted by <a href="https://iclr-r2fm.github.io" style="font-size:18px; font-weight:normal; text-decoration:underline;">ICLR 2024 R2-FM Workshop</a>! Stay tuned for the details.
                      </span>
                    </papertitle>
                    <br>
                  </p>
              </td>
          </tr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading> <font size="6"> Publications </font></heading>
                  <p>
                    <heading> <font size="5">International </font></heading>
                    <p>
                    <!-- <heading> <font size="4">2023</font></heading>
                    <ul> -->
                      <ul>
                      <li><papertitle> <font size="3"> Can Pre-trained Networks Detect Familiar Out-of-Distribution Data? </font></papertitle> <br>
                        <u>Atsuyuki Miyai</u>,
                        <a href="https://yu1ut.com/">Qing Yu</a>, 
                        <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/">Go Irie</a>, 
                        <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja">Kiyoharu Aizawa</a>
                        <br>
                        <em>arXiv, 2023</em>
                        <br>
                        <a href="http://arxiv.org/abs/2310.00847">paper</a> &nbsp/&nbsp
                        <a href="https://github.com/AtsuMiyai/PT-OOD">code</a> (comming soon)</li> </li>
                        <div class="col-md-5">
                          <a href="">
                              <img class="img-responsive img-hover" src="images/PT-OOD/decision_boundary.png"  width = "600 px" ></a>
                        </div>
                        <br><br>
                      <li><papertitle> <font size="3"> LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning </font></papertitle> <br>
                        <u>Atsuyuki Miyai</u>,
                        <a href="https://yu1ut.com/">Qing Yu</a>, 
                        <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/">Go Irie</a>, 
                        <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja">Kiyoharu Aizawa</a>
                        <br>
                        <em>Neural Information Processing Systems (NeurIPS), 2023</em>
                        <br>
                        <a href="https://arxiv.org/abs/2306.01293">paper</a> &nbsp/&nbsp
                        <a href="https://github.com/AtsuMiyai/LoCoOp">code</a></li> </li>
                        <div class="col-md-5">
                          <a href="">
                              <img class="img-responsive img-hover" src="images/LoCoOp/framework.png"  width = "550 px" ></a>
                        </div>
                    <br><br>
                    <li><papertitle> <font size="3"> Zero-Shot In-Distribution Detection in Multi-Object Settings Using Vision-Language Foundation Models </font></papertitle> <br>
                      <u>Atsuyuki Miyai</u>,
                      <a href="https://yu1ut.com/">Qing Yu</a>, 
                      <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/">Go Irie</a>, 
                      <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja">Kiyoharu Aizawa</a>
                      <br>
                      <em>arXiv, 2023</em>
                      <br>
                      <a href="https://arxiv.org/abs/2304.04521">paper</a> &nbsp/&nbsp
                      <a href="https://github.com/AtsuMiyai/GL-MCM">code</a> </li> </li>
                      <div class="col-md-5">
                        <a href="">
                            <img class="img-responsive img-hover" src="images/id_detection/id_detection.png"  width = "600 px" ></a>
                      </div>
                    </p>
                    <br>
                    <!-- <heading> <font size="5">International</font></heading>
                    <p>
                    <heading> <font size="4">2023</font></heading> -->
                    <li><papertitle> <font size="3"> Rethinking Rotation in Self-Supervised Contrastive Learning: Adaptive Positive or Negative Data Augmentation </font></papertitle> <br>
                    <u>Atsuyuki Miyai</u>,
                    <a href="https://yu1ut.com/">Qing Yu</a>, 
                    Daiki Ikami, 
                    <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/">Go Irie</a>, 
                    <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja">Kiyoharu Aizawa</a>
                    <br>
                    <em>Winter Conference on Applications of Computer Vision (WACV), 2023</em>
                    <br>
                    <a href="http://arxiv.org/abs/2210.12681">paper</a> &nbsp/&nbsp
                    <a href="https://github.com/chibechan/rethinking_rotation">code</a> </li>
                    <div class="col-md-5">
                      <a href="">
                          <img class="img-responsive img-hover" src="images/pnda/pnda.png"  width = "450 px" ></a>
                    </div>
                    </ul>
                    </p>
                    <br>
                    <heading> <font size="5">Domestic (Japanese, Non-refereed)</font></heading>
                    <p>
                    <ul>
                      <li><papertitle> <font size="3"> CLIPを用いたゼロショット分布内検知 </font></papertitle> <br>
                        <u>宮井 淳行</u>,
                      <a href="https://yu1ut.com/">郁 青</a>, 
                      <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/">入江 豪</a>, 
                      <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja">相澤 清晴</a>
                        <br>
                        <em>IE, 2024, <font color="red"> IE Award </font> </em>
                        <br><br>
                    <li><papertitle> <font size="3"> CLIP-based In-distribution Detection </font></papertitle> <br>
                      <u>Atsuyuki Miyai</u>,
                      <a href="https://yu1ut.com/">Qing Yu</a>, 
                      <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/">Go Irie</a>, 
                      <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja">Kiyoharu Aizawa</a>
                      <br>
                      <em>MIRU, 2023 (short oral) </em>
                      <br><br>
                    <li><papertitle> <font size="3"> Rethinking Rotation for Contrastive Learning: Adaptive Positive or Negative Data Augmentation </font></papertitle> <br>
                    <u>Atsuyuki Miyai</u>,
                    <a href="https://yu1ut.com/">Qing Yu</a>, 
                    Daiki Ikami, 
                    <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/">Go Irie</a>, 
                    <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja">Kiyoharu Aizawa</a>
                    <br>
                    <em>MIRU, 2022 (long oral), <font color="red"> Best Student Paper </font> </em>
                    <br><br>
                    <li><papertitle> <font size="3"> 自己教師あり学習のための適応的正負例データ拡張 </font></papertitle> <br>
                      <u>宮井 淳行</u>,
                      <a href="https://yu1ut.com/">郁 青</a>, 
                      伊神大貴, 
                      <a href="https://scholar.google.co.jp/citations?user=2bCSG1AAAAAJ&hl=en/">入江 豪</a>, 
                      <a href="https://scholar.google.co.jp/citations?user=CJRhhi0AAAAJ&hl=ja">相澤 清晴</a>
                      <br>
                      <em>IPSJ (情報処理学会), 2022, <font color="red"> Student Encouragement Award </font> </em>
                    <br>
                    </ul>
                  </p>
                  </p>
              </td>
          </tr>
          
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <heading> <font size="6"> Awards </font></heading>
                <p>
                  <papertitle><font size="4">2024.3:</font> <font size="4">The Dean's Award, The Best Master Thesis Award</font></papertitle> <br>
                </p>
                <p>
                  <papertitle><font size="4">2024.2:</font> <font size="4"> IE Award @<em>IE (画像工学研究会) Feb. 2024</em></font></papertitle> <br>
                </p>
                <p>
                  <papertitle><font size="4">2023.7:</font> <font size="4"> Interactive Presentation Award @<em>MIRU 2023</em></font></papertitle> <br>
                </p>
                <p>
                  <papertitle><font size="4">2022.7:</font> <font size="4"> Best Student Paper Award @<em>MIRU 2022</em></font></papertitle> <br>
                  Awarded The Best Student Paper Award by The Association for Meeting on Image Recognition and Understanding  (Japanese representative scientific and professional society for researchers working on problems involving computer vision). <br>
                  Please refer to <a href="https://sites.google.com/view/miru2022/home/award?authuser=0">the official homepage</a>.
                </p>
                <p>
                  <papertitle><font size="4">2022.3:</font> <font size="4"> Student Encouragement Award @<em>Information Processing Society of Japan (IPSJ) 2022</em></font></papertitle> <br>
                </p>
            </td>
        </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
              <heading> <font size="6"> Internship </font></heading>
              <p>
                <papertitle><font size="4">2023.6 ~ 2023.12:</font>    <font size="4"> OMRON SINICX  </font></papertitle> <br>
                Research Internship.&nbsp;&nbsp; Mentor: <a href="https://yoshitakaushiku.net/index_ja.html">Dr.  Yoshitaka Ushiku</a>, <a href="https://atsushihashimoto.github.io/cv/">Dr. Atsushi Hashimoto</a>, <a href="https://ksaito-ut.github.io/">Dr. Kuniaki Saito</a>
                <div class="col-md-5">
                  <a href="">
                      <img class="img-responsive img-hover" src="images/internship/omron-logo.svg"  width = "150 px" ></a>
                </div>
              </p>
              <br>
              <p>
                <papertitle><font size="4">2022.8 ~ 2022.9:</font>    <font size="4">   Preferred Networks </font></papertitle> <br>
                Research Internship.&nbsp;&nbsp; Mentor: <a href="https://scholar.google.co.jp/citations?user=oY1gA10AAAAJ&hl=en">Dr. Masanori Koyama</a>, <a href="https://scholar.google.com/citations?user=lDXTuNIAAAAJ&hl=ja">Dr. Kohei Hayashi</a>, <a href="https://scholar.google.com/citations?user=UwuggM4AAAAJ&hl=ja">Dr. Yuta Kikuchi</a>, Dr. Yoshihiro Yamada
                <div class="col-md-5">
                  <a href="">
                      <img class="img-responsive img-hover" src="images/internship/pfn.png"  width = "250 px" ></a>
                </div>
              </p>
              <br>
              <p>
                <papertitle><font size="4">2020.10 ~ 2023.03:</font>    <font size="4">   Pluszero Inc.  </font></papertitle> <br>
                Project Engineer. &nbsp;I tackle natural language processing.
                <div class="col-md-5">
                  <a href="">
                      <img class="img-responsive img-hover" src="images/internship/pluszero.png"  width = "200 px" ></a>
                </div>
              </p>
          </td>
      </tr>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <heading> <font size="6"> Academic activities </font></heading>
                <p>
                  <papertitle><font size="4">2023.12 ~ :</font>    <font size="4"> OpenOOD </font></papertitle> <br>
                  Research activities. &nbsp; Collaborators (≒Mentors): <a href="https://jingkang50.github.io/">Jingkang Yang</a> (Nanyang Technological University), <a href="https://scholar.google.com/citations?user=f3DQwmgAAAAJ&hl=en"> Jinyang Zhang</a> (Duke University)
                  <div class="col-md-5">
                    <a href="">
                        <img class="img-responsive img-hover" src="images/openOOD/openood.png"  width = "250 px" ></a>
                  </div>
                  <br>
                </p>
                  <p>
                  <papertitle><font size="4">2023.4 ~ :</font>    <font size="4"> IEEE Student Branch Chair @UTokyo  </font></papertitle> <br>
                  We have a diverse range of workshops, invited talks, and hands-on activities focused on advancing knowledge and skills in a particular field or topic. 
                  Please feel free to contact us when you visit Tokyo! <br>
                  Please refer to <a href="https://sites.google.com/g.ecc.u-tokyo.ac.jp/ieee-student-branch/home?authuser=0">the official homepage</a>.
                </p>
                <br>
                  <papertitle> <font size="4"> Review experience  </font></papertitle> <br>
                  CVPR2024, MIRU2024 (Japanese conference)
            </td>
        </tr>
        
      </td>
    </tr>
  </tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe>
  <div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div>
</body>

</html>